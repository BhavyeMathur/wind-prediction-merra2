{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-27T07:28:18.376758Z",
     "start_time": "2023-07-27T07:28:15.629630Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbhavye-mathur\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "from WindModel import *\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEVICE = \"mps\"\n",
    "QUANTILE = None\n",
    "\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "LOSS_FUNC = torch.nn.MSELoss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T07:28:18.379322Z",
     "start_time": "2023-07-27T07:28:18.377142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../data/subset/V-NGCTCC-10000000.ft\n"
     ]
    }
   ],
   "source": [
    "WindDataset.init(1, predict_difference=False, cyclic_coordinates=True, barometric=False, mathur2022=False,\n",
    "                 quantile=QUANTILE, variables=(\"V\",), geographical_matrix=1, device=DEVICE)\n",
    "\n",
    "train = WindDataset(\"train\")\n",
    "validation = WindDataset(\"validation\")\n",
    "test = WindDataset(\"test\")\n",
    "\n",
    "del WindDataset.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T07:28:32.798644Z",
     "start_time": "2023-07-27T07:28:30.122363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "19"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SIZE = train.x.shape[-1]\n",
    "INPUT_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T07:28:32.801273Z",
     "start_time": "2023-07-27T07:28:32.799315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_dense_model(input_size: int,\n",
    "                    hidden_sizes: list[int],\n",
    "                    output_size: int,\n",
    "                    activation_func: callable):\n",
    "    layers = []\n",
    "\n",
    "    for size in hidden_sizes:\n",
    "        layers.append(torch.nn.Linear(input_size, size))\n",
    "        layers.append(activation_func())\n",
    "        input_size = size\n",
    "\n",
    "    layers.append(torch.nn.Linear(input_size, output_size))\n",
    "\n",
    "    return torch.nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T07:28:32.803954Z",
     "start_time": "2023-07-27T07:28:32.802464Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SinusoidalLayer(torch.nn.Module):\n",
    "    def __init__(self, size_in: int, size_out: int, device=\"mps\", dtype=None):\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "\n",
    "        super().__init__()\n",
    "        self.size_in = size_in\n",
    "        self.size_out = size_out\n",
    "\n",
    "        self.periods = torch.linspace(0.01, 100, size_out, **factory_kwargs).repeat((size_in, 1))\n",
    "\n",
    "        self.weights = torch.nn.Parameter(torch.empty((size_out, size_out), **factory_kwargs))\n",
    "        self.phase = torch.nn.Parameter(torch.zeros(size_out, **factory_kwargs))\n",
    "        # self.bias = torch.nn.Parameter(torch.empty(size_out, **factory_kwargs))\n",
    "\n",
    "        torch.nn.init.kaiming_uniform_(self.weights, a=2.236)\n",
    "        fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
    "        # bound = 1 / (fan_in ** 0.5)\n",
    "        # torch.nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.mm(x, self.periods)\n",
    "        out = torch.add(out, self.phase)\n",
    "        out = torch.sin(out)\n",
    "        out = torch.mm(out, self.weights)\n",
    "        # out = torch.add(out, self.bias)\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_sinusoidal_model(input_size: int,\n",
    "                         periods: int,\n",
    "                         hidden_sizes: list[int],\n",
    "                         output_size: int,\n",
    "                         activation_func: callable):\n",
    "    layers = [SinusoidalLayer(input_size, periods),\n",
    "              activation_func()]\n",
    "    input_size = periods\n",
    "\n",
    "    for size in hidden_sizes:\n",
    "        layers.append(torch.nn.Linear(input_size, size))\n",
    "        layers.append(activation_func())\n",
    "        input_size = size\n",
    "\n",
    "    layers.append(torch.nn.Linear(input_size, output_size))\n",
    "\n",
    "    return torch.nn.Sequential(*layers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T07:28:32.808425Z",
     "start_time": "2023-07-27T07:28:32.807009Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def evaluate_one_epoch(model, epoch):\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(validation.x).squeeze()\n",
    "\n",
    "        mse += torch.nn.functional.mse_loss(prediction, validation.y)\n",
    "        mae += torch.nn.functional.l1_loss(prediction, validation.y)\n",
    "\n",
    "    val_rmse = (mse ** 0.5) * stds[VARIABLE]\n",
    "\n",
    "    wandb.log({\"val_rmse\": val_rmse,\n",
    "               \"val_mae\": mae * stds[VARIABLE]})\n",
    "\n",
    "    return val_rmse\n",
    "\n",
    "\n",
    "def train_one_batch(model, optimizer, criterion, batch, batch_idx):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs, targets = batch\n",
    "\n",
    "    prediction = model(inputs).squeeze()\n",
    "    loss = criterion(prediction, targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx != 0 and batch_idx % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            rmse = (torch.nn.functional.mse_loss(prediction, targets) ** 0.5) * stds[VARIABLE]\n",
    "            wandb.log({\"train_loss\": loss,\n",
    "                       \"train_rmse\": rmse})\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, criterion, epoch, batch_size):\n",
    "    n = len(train)\n",
    "\n",
    "    for i in range(len(train) // batch_size):\n",
    "        lower_i = i * batch_size\n",
    "        upper_i = min((i + 1) * batch_size, n)\n",
    "\n",
    "        batch_x = train.x[lower_i: upper_i]\n",
    "        batch_y = train.y[lower_i: upper_i]\n",
    "\n",
    "        train_one_batch(model, optimizer, criterion, (batch_x, batch_y), i)\n",
    "\n",
    "\n",
    "def main(conf=None):\n",
    "    wandb.init(project=f\"MERRA2-{VARIABLE}-July2023\", config=conf)\n",
    "\n",
    "    # learning_rate = wandb.config.learning_rate\n",
    "    batch_size = wandb.config.batch_size\n",
    "    layers = wandb.config.layers\n",
    "    epochs = wandb.config.epochs\n",
    "    activation = wandb.config.activation\n",
    "\n",
    "    activation = getattr(torch.nn, activation)\n",
    "\n",
    "    model = get_dense_model(INPUT_SIZE, layers, OUTPUT_SIZE, activation)\n",
    "    model = model.to(DEVICE)\n",
    "    print(model)\n",
    "\n",
    "    criterion = LOSS_FUNC()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    if (scheduler := wandb.config.lr_scheduler) is None:\n",
    "        scheduler = None\n",
    "    else:\n",
    "        scheduler = getattr(torch.optim.lr_scheduler, scheduler)(optimizer, **wandb.config.lr_scheduler_kwargs)\n",
    "\n",
    "    if DEVICE != \"mps\":\n",
    "        wandb.watch(model, log_freq=10)\n",
    "\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        print(ep, end=\" \")\n",
    "\n",
    "        wandb.log({\"epoch\": ep})\n",
    "\n",
    "        model.train()\n",
    "        train_one_epoch(model, optimizer, criterion, ep, batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        val_rmse = evaluate_one_epoch(model, ep)\n",
    "\n",
    "        if wandb.config.lr_scheduler == \"ReduceLROnPlateau\":\n",
    "            scheduler.step(val_rmse)\n",
    "            wandb.log({\"lr\": optimizer.param_groups[0][\"lr\"]})\n",
    "        elif scheduler:\n",
    "            scheduler.step()\n",
    "            wandb.log({\"lr\": scheduler.get_last_lr()[-1]})\n",
    "\n",
    "    # torch.save(model, os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T07:28:32.814316Z",
     "start_time": "2023-07-27T07:28:32.812808Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:gf3np19u) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "365856cff2c7443cadb9e63b30ce9ace"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▄▃▅▅▄▄▂▄▄▃▃▃▁▄▂▃▃▂▃▄▂▃▂▁▄▂▂▂▁▂▄▁▃▂▃▄▁▂▂</td></tr><tr><td>train_rmse</td><td>█▅▃▅▅▄▄▂▄▄▃▄▃▁▄▂▃▃▂▄▅▂▄▂▁▄▂▂▂▁▂▄▂▃▂▃▄▂▂▂</td></tr><tr><td>val_mae</td><td>█▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_rmse</td><td>█▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>28</td></tr><tr><td>train_loss</td><td>0.3552</td></tr><tr><td>train_rmse</td><td>1.92623</td></tr><tr><td>val_mae</td><td>1.43204</td></tr><tr><td>val_rmse</td><td>1.94773</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">neat-water-4</strong> at: <a href='https://wandb.ai/bhavye-mathur/MERRA2-V-July2023/runs/gf3np19u' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-V-July2023/runs/gf3np19u</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20230727_125840-gf3np19u/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:gf3np19u). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016753370133422627, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b521048d2044762b15422f5d851766f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/bhavyemathur/Desktop/Projects/Spherindrical Fourier Transform/MERRA-2/wind-prediction/models/wandb/run-20230727_131939-35itooum</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/bhavye-mathur/MERRA2-V-July2023/runs/35itooum' target=\"_blank\">different-sea-5</a></strong> to <a href='https://wandb.ai/bhavye-mathur/MERRA2-V-July2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/bhavye-mathur/MERRA2-V-July2023' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-V-July2023</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/bhavye-mathur/MERRA2-V-July2023/runs/35itooum' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-V-July2023/runs/35itooum</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=19, out_features=512, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b4971241a094082b64f3ba61e72bfc7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.001,\n",
    "    # \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    # \"lr_scheduler_kwargs\": {},\n",
    "\n",
    "    \"lr_scheduler\": \"StepLR\",\n",
    "    \"lr_scheduler_kwargs\": {\"step_size\": 18, \"gamma\": 0.7},\n",
    "\n",
    "    \"lr_scheduler\": None,\n",
    "\n",
    "    \"layers\": [512, 256, 128],\n",
    "    \"activation\": \"Tanh\",\n",
    "    # \"estimate_quantile\": QUANTILE,\n",
    "    \"dataset\": \"MATHUR2022\",\n",
    "    \"epochs\": 200,\n",
    "}\n",
    "\n",
    "model = main(config)\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-27T07:49:39.053524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "torch.save(model, \"FNN/V-1024-512-256-LeakyReLU-NGCTCC-radiant-wave-1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T08:04:48.899720Z",
     "start_time": "2023-07-26T08:04:48.898468Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"name\": f\"sweep-NGCTCC\",\n",
    "    \"metric\": {\n",
    "        \"goal\": \"minimize\",\n",
    "        \"name\": \"val_rmse\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [1024, 2048, 4096, 8192]},\n",
    "        # \"learning_rate\": {\"max\": 0.01, \"min\": 0.00001},\n",
    "        \"lr_scheduler\": {\"value\": None},\n",
    "        \"lr_scheduler_kwargs\": {\"parameters\": {\"step_size\": {\"max\": 20, \"min\": 10},\n",
    "                                               \"gamma\": {\"max\": 0.85, \"min\": 0.5}}},\n",
    "        \"layers\":\n",
    "            # {\"values\": [(256, 128), (512, 256), (1024, 512), (2048, 1024)]},\n",
    "            # {\"values\": [(256, 128), (512, 256), (1024, 512), (1024, 512, 256), (256, 256, 32), (512, 256, 128), (128, 64, 32)]},\n",
    "            {\"values\": [(1024, 512, 256), (512, 256, 128), (256, 128, 64)]},\n",
    "        \"epochs\": {\"value\": 100},\n",
    "        \"activation\":\n",
    "            {\"values\": [\"ReLU\", \"PReLU\", \"LeakyReLU\", \"Tanh\"]},\n",
    "        # \"estimate_quantile\": {\"value\": QUANTILE},\n",
    "        \"dataset\": {\"value\": \"NGCTCC\"},\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 3,\n",
    "        \"eta\": 2\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f\"MERRA2-{VARIABLE}-July2023\")\n",
    "wandb.agent(sweep_id, function=main)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=19, out_features=1024, bias=True)\n  (1): LeakyReLU(negative_slope=0.01)\n  (2): Linear(in_features=1024, out_features=512, bias=True)\n  (3): LeakyReLU(negative_slope=0.01)\n  (4): Linear(in_features=512, out_features=256, bias=True)\n  (5): LeakyReLU(negative_slope=0.01)\n  (6): Linear(in_features=256, out_features=1, bias=True)\n)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"FNN/U-1024-512-256-LeakyReLU-NGCTCC-hardy-bee-540\")\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T04:02:26.084838Z",
     "start_time": "2023-07-26T04:02:26.059058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Original Stdev: 3.2307777404785156 m/s\n",
      "    Predicted MAE:  1.232912540435791 m/s\n",
      "    Predicted RMSE: 1.7036985158920288 m/s\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = model(test.x).squeeze() * stds[VARIABLE] + means[VARIABLE]\n",
    "    target = test.y * stds[VARIABLE] + means[VARIABLE]\n",
    "\n",
    "    lines = f\"\"\"\n",
    "    Original Stdev: {torch.std(target)} m/s\n",
    "    Predicted MAE:  {torch.nn.functional.l1_loss(prediction, target)} m/s\n",
    "    Predicted RMSE: {torch.nn.functional.mse_loss(prediction, target) ** 0.5} m/s\n",
    "    \"\"\"\n",
    "    print(lines)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T08:05:01.138813Z",
     "start_time": "2023-07-26T08:04:59.977584Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
