{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:40:14.847666Z",
     "start_time": "2023-07-20T10:40:11.838804Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbhavye-mathur\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "from WindModel import *\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "WindDataset.init(0.1)\n",
    "\n",
    "train = WindDataset(\"train\")\n",
    "validation = WindDataset(\"validation\")\n",
    "test = WindDataset(\"test\")\n",
    "\n",
    "del WindDataset.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:40:21.816207Z",
     "start_time": "2023-07-20T10:40:14.849396Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "OUTPUT_SIZE = 1\n",
    "INPUT_SIZE = 13\n",
    "\n",
    "LOSS_FUNC = torch.nn.MSELoss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:40:21.818164Z",
     "start_time": "2023-07-20T10:40:21.816465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_dense_model(input_size: int,\n",
    "                    hidden_sizes: list[int],\n",
    "                    output_size: int,\n",
    "                    activation_func: callable):\n",
    "    layers = []\n",
    "\n",
    "    for size in hidden_sizes:\n",
    "        layers.append(torch.nn.Linear(input_size, size))\n",
    "        layers.append(activation_func())\n",
    "        input_size = size\n",
    "\n",
    "    layers.append(torch.nn.Linear(input_size, output_size))\n",
    "\n",
    "    return torch.nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:40:21.820641Z",
     "start_time": "2023-07-20T10:40:21.819491Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class SinusoidalLayer(torch.nn.Module):\n",
    "    def __init__(self, size_in: int, size_out: int, device=None, dtype=None):\n",
    "        factory_kwargs = {'device': DEVICE, 'dtype': dtype}\n",
    "\n",
    "        super().__init__()\n",
    "        self.size_in = size_in\n",
    "        self.size_out = size_out\n",
    "\n",
    "        self.periods = torch.linspace(0.01, 100, size_out, **factory_kwargs).repeat((size_in, 1))\n",
    "\n",
    "        self.weights = torch.nn.Parameter(torch.empty((size_out, size_out), **factory_kwargs))\n",
    "        self.phase = torch.nn.Parameter(torch.zeros(size_out, **factory_kwargs))\n",
    "        # self.bias = torch.nn.Parameter(torch.empty(size_out, **factory_kwargs))\n",
    "\n",
    "        torch.nn.init.kaiming_uniform_(self.weights, a=2.236)\n",
    "        fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
    "        bound = 1 / (fan_in ** 0.5)\n",
    "        # torch.nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.mm(x, self.periods)\n",
    "        out = torch.add(out, self.phase)\n",
    "        out = torch.sin(out)\n",
    "        out = torch.mm(out, self.weights)\n",
    "        # out = torch.add(out, self.bias)\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_sinusoidal_model(input_size: int,\n",
    "                         periods: int,\n",
    "                         hidden_sizes: list[int],\n",
    "                         output_size: int,\n",
    "                         activation_func: callable):\n",
    "    layers = [SinusoidalLayer(input_size, periods),\n",
    "              activation_func()]\n",
    "    input_size = periods\n",
    "\n",
    "    for size in hidden_sizes:\n",
    "        layers.append(torch.nn.Linear(input_size, size))\n",
    "        layers.append(activation_func())\n",
    "        input_size = size\n",
    "\n",
    "    layers.append(torch.nn.Linear(input_size, output_size))\n",
    "\n",
    "    return torch.nn.Sequential(*layers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:40:21.825552Z",
     "start_time": "2023-07-20T10:40:21.824620Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def evaluate_one_epoch(model, epoch):\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(validation.x).squeeze()\n",
    "\n",
    "        mse += torch.nn.functional.mse_loss(prediction, validation.y)\n",
    "        mae += torch.nn.functional.l1_loss(prediction, validation.y)\n",
    "\n",
    "    wandb.log({\"val_rmse\": (mse ** 0.5) * stds[VARIABLE],\n",
    "               \"val_mae\": mae * stds[VARIABLE]})\n",
    "\n",
    "\n",
    "def train_one_batch(model, optimizer, criterion, batch, batch_idx):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs, targets = batch\n",
    "\n",
    "    prediction = model(inputs).squeeze()\n",
    "    loss = criterion(prediction, targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx != 0 and batch_idx % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            rmse = (torch.nn.functional.mse_loss(prediction, targets) ** 0.5) * stds[VARIABLE]\n",
    "            wandb.log({\"train_loss\": loss,\n",
    "                       \"train_rmse\": rmse})\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, criterion, epoch, batch_size):\n",
    "    n = len(train)\n",
    "\n",
    "    for i in range(len(train) // batch_size):\n",
    "        lower_i = i * batch_size\n",
    "        upper_i = min((i + 1) * batch_size, n)\n",
    "\n",
    "        batch_x = train.x[lower_i: upper_i]\n",
    "        batch_y = train.y[lower_i: upper_i]\n",
    "\n",
    "        train_one_batch(model, optimizer, criterion, (batch_x, batch_y), i)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # wandb.init()\n",
    "\n",
    "    learning_rate = wandb.config.learning_rate\n",
    "    batch_size = wandb.config.batch_size\n",
    "    layers = wandb.config.layers\n",
    "    periods = wandb.config.periods\n",
    "    epochs = wandb.config.epochs\n",
    "    activation = wandb.config.activation\n",
    "\n",
    "    activation = getattr(torch.nn, activation)\n",
    "\n",
    "    model = get_dense_model(INPUT_SIZE, layers, OUTPUT_SIZE, activation)\n",
    "    model = model.to(DEVICE)\n",
    "    print(model)\n",
    "\n",
    "    criterion = LOSS_FUNC()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if (scheduler := wandb.config.lr_scheduler) is None:\n",
    "        scheduler = None\n",
    "    elif scheduler == \"StepLR\":\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, **wandb.config.lr_scheduler_kwargs)\n",
    "\n",
    "    # wandb.watch(model, log_freq=100)\n",
    "\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        print(ep, end=\" \")\n",
    "\n",
    "        wandb.log({\"epoch\": ep})\n",
    "\n",
    "        model.train()\n",
    "        train_one_epoch(model, optimizer, criterion, ep, batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        evaluate_one_epoch(model, ep)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            wandb.log({\"lr\": scheduler.get_last_lr()[-1]})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T10:46:30.824839Z",
     "start_time": "2023-07-20T10:46:30.819954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:lls3jb9h) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dadd90c60a44a75b694017acd841f9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_rmse</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▆▄▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_rmse</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>lr</td><td>0.0005</td></tr><tr><td>train_loss</td><td>0.26701</td></tr><tr><td>train_rmse</td><td>5.08044</td></tr><tr><td>val_mae</td><td>3.62003</td></tr><tr><td>val_rmse</td><td>5.05532</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">zany-serenity-261</strong> at: <a href='https://wandb.ai/bhavye-mathur/MERRA2-U-July2023/runs/lls3jb9h' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-U-July2023/runs/lls3jb9h</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>wandb-local/wandb/run-20230720_161127-lls3jb9h/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:lls3jb9h). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01675102916584971, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9147007b777b47b1ac5bf75d6fe01bd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>wandb-local/wandb/run-20230720_161631-p0lrrqhv</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/bhavye-mathur/MERRA2-U-July2023/runs/p0lrrqhv' target=\"_blank\">light-violet-262</a></strong> to <a href='https://wandb.ai/bhavye-mathur/MERRA2-U-July2023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/bhavye-mathur/MERRA2-U-July2023' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-U-July2023</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/bhavye-mathur/MERRA2-U-July2023/runs/p0lrrqhv' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-U-July2023/runs/p0lrrqhv</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=1024, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6dba5ce7db8b4d048b2011e61db1a18e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 16\u001B[0m\n\u001B[1;32m      1\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m65536\u001B[39m,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0.0005\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mperiods\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1024\u001B[39m,\n\u001B[1;32m     12\u001B[0m }\n\u001B[1;32m     14\u001B[0m wandb\u001B[38;5;241m.\u001B[39minit(project\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMERRA2-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVARIABLE\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-July2023\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mdir\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwandb-local\u001B[39m\u001B[38;5;124m\"\u001B[39m, config\u001B[38;5;241m=\u001B[39mconfig)\n\u001B[0;32m---> 16\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m wandb\u001B[38;5;241m.\u001B[39mfinish()\n",
      "Cell \u001B[0;32mIn[8], line 78\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     75\u001B[0m wandb\u001B[38;5;241m.\u001B[39mlog({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m: ep})\n\u001B[1;32m     77\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 78\u001B[0m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     81\u001B[0m evaluate_one_epoch(model, ep)\n",
      "Cell \u001B[0;32mIn[8], line 43\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[0;34m(model, optimizer, criterion, epoch, batch_size)\u001B[0m\n\u001B[1;32m     40\u001B[0m batch_x \u001B[38;5;241m=\u001B[39m train\u001B[38;5;241m.\u001B[39mx[lower_i: upper_i]\n\u001B[1;32m     41\u001B[0m batch_y \u001B[38;5;241m=\u001B[39m train\u001B[38;5;241m.\u001B[39my[lower_i: upper_i]\n\u001B[0;32m---> 43\u001B[0m \u001B[43mtrain_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_y\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 20\u001B[0m, in \u001B[0;36mtrain_one_batch\u001B[0;34m(model, optimizer, criterion, batch, batch_idx)\u001B[0m\n\u001B[1;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     18\u001B[0m inputs, targets \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m---> 20\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[1;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(prediction, targets)\n\u001B[1;32m     23\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/Desktop/Projects/Spherindrical Fourier Transform/MERRA-2/wind-prediction/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Desktop/Projects/Spherindrical Fourier Transform/MERRA-2/wind-prediction/venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/Projects/Spherindrical Fourier Transform/MERRA-2/wind-prediction/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Desktop/Projects/Spherindrical Fourier Transform/MERRA-2/wind-prediction/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"batch_size\": 65536,\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"lr_scheduler\": \"StepLR\",\n",
    "    \"lr_scheduler_kwargs\": {\"step_size\": 16, \"gamma\": 0.3},\n",
    "    \"layers\": [1024, 512],\n",
    "    \"activation\": \"LeakyReLU\",\n",
    "    \"estimate_quantile\": ESTIMATE_QUANTILE,\n",
    "    \"dataset\": DATASET,\n",
    "    \"epochs\": 40,\n",
    "    \"periods\": 1024,\n",
    "}\n",
    "\n",
    "wandb.init(project=f\"MERRA2-{VARIABLE}-July2023\", dir=\"wandb-local\", config=config)\n",
    "\n",
    "main()\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-07-20T10:55:27.619967Z",
     "start_time": "2023-07-20T10:46:31.912877Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"name\": f\"sweep-{DATASET}-Sinusoidal\",\n",
    "    \"metric\": {\n",
    "        \"goal\": \"minimize\",\n",
    "        \"name\": \"val_rmse\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [8192, 16384, 32768, 65536]},\n",
    "        \"periods\": {\"values\": [32, 64, 128, 256, 512, 1024]},\n",
    "        \"learning_rate\": {\"max\": 0.001, \"min\": 0.00001},\n",
    "        \"lr_scheduler\": {\"values\": [None, \"StepLR\"]},\n",
    "        \"lr_scheduler_kwargs\": {\"parameters\": {\"step_size\": {\"max\": 20, \"min\": 10},\n",
    "                                               \"gamma\": {\"max\": 0.85, \"min\": 0.15}}},\n",
    "        \"layers\": {\"values\": [(256, 128), (512, 256), (1024, 512),\n",
    "                              (1024, 512, 256), (256, 256, 32), (512, 256, 128), (128, 64, 32)]},\n",
    "        \"epochs\": {\"value\": 40},\n",
    "        \"activation\": {\"values\": [\"ReLU\", \"PReLU\", \"LeakyReLU\", \"ELU\", \"Softplus\"]},\n",
    "        \"estimate_quantile\": {\"value\": ESTIMATE_QUANTILE},\n",
    "        \"dataset\": {\"value\": DATASET},\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"min_iter\": 3,\n",
    "        \"eta\": 2\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f\"MERRA2-{VARIABLE}-July2023\")\n",
    "wandb.agent(sweep_id, function=main)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(model, dl):\n",
    "    model.eval()\n",
    "\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dl):\n",
    "            prediction = model(inputs).squeeze()\n",
    "\n",
    "            mse += torch.nn.functional.mse_loss(prediction, targets)\n",
    "            mae += torch.nn.functional.l1_loss(prediction, targets)\n",
    "\n",
    "    return (mse / len(dl)) ** 0.5 * stds[VARIABLE], (mae / len(dl)) * stds[VARIABLE]\n",
    "\n",
    "\n",
    "test_dl = DataLoader(test, batch_size=2048, shuffle=False)\n",
    "test_rmse, test_mae = test(model, test)\n",
    "\n",
    "print(f\"RMSE: {test_rmse} m/s\")\n",
    "print(f\"MAE:  {test_mae} m/s\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
