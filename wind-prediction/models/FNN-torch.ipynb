{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbhavye-mathur\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_dense_model(input_size: int,\n",
    "                    hidden_sizes: list[int],\n",
    "                    output_size: int,\n",
    "                    activation_func: callable):\n",
    "    layers = []\n",
    "\n",
    "    for size in hidden_sizes:\n",
    "        layers.append(torch.nn.Linear(input_size, size))\n",
    "        layers.append(activation_func())\n",
    "        input_size = size\n",
    "\n",
    "    layers.append(torch.nn.Linear(input_size, output_size))\n",
    "\n",
    "    return torch.nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "means = {\"U\": 5.589, \"V\": 0.018}\n",
    "stds = {\"U\": 9.832, \"V\": 3.232}\n",
    "\n",
    "ESTIMATE_QUANTILE = 0.9935\n",
    "N = 100000000\n",
    "\n",
    "BATCH_SIZE = 2056\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "TRAIN_VAL_SPLIT = 0.9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class WindDataset(Dataset):\n",
    "    data: pd.DataFrame\n",
    "\n",
    "    def __init__(self, variable: str, subset: str):\n",
    "        if subset == \"train\":\n",
    "            self.x = self.data.iloc[:int(len(self.data) * TRAIN_TEST_SPLIT)]\n",
    "            self.x = self.data.iloc[:int(len(self.x) * TRAIN_VAL_SPLIT)]\n",
    "        elif subset == \"test\":\n",
    "            self.x = self.data.iloc[int(len(self.data) * TRAIN_TEST_SPLIT):]\n",
    "        elif subset == \"validation\":\n",
    "            self.x = self.data.iloc[:int(len(self.data) * TRAIN_TEST_SPLIT)]\n",
    "            self.x = self.data.iloc[int(len(self.x) * TRAIN_VAL_SPLIT):]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Subset\")\n",
    "\n",
    "        self.y = self.x[variable]\n",
    "\n",
    "        del self.x[\"U\"]\n",
    "        del self.x[\"V\"]\n",
    "\n",
    "        self.x = self.x.values.astype(\"float32\")\n",
    "        self.y = self.y.values.astype(\"float32\")\n",
    "\n",
    "        self.x = torch.Tensor(self.x).to(DEVICE)\n",
    "        self.y = torch.Tensor(self.y).to(DEVICE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "\n",
    "    @classmethod\n",
    "    def init(cls, frac: float):\n",
    "        cls.data = pd.read_feather(f\"../raw/subset/UV-NGCT-{ESTIMATE_QUANTILE}-{100000000}.ft\").sample(frac=frac)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "VARIABLE = \"U\"\n",
    "\n",
    "WindDataset.init(0.1)\n",
    "\n",
    "train = WindDataset(VARIABLE, \"train\")\n",
    "validation = WindDataset(VARIABLE, \"validation\")\n",
    "test = WindDataset(VARIABLE, \"test\")\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dl = DataLoader(validation, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "del WindDataset.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "INPUT_SIZE = 15\n",
    "OUTPUT_SIZE = 1\n",
    "HIDDEN_SIZES = [512, 256]\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "ACTIVATION = torch.nn.ReLU\n",
    "LOSS_FUNC = torch.nn.MSELoss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=15, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=512, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=1, bias=True)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_dense_model(INPUT_SIZE, HIDDEN_SIZES, OUTPUT_SIZE, ACTIVATION)\n",
    "model = model.to(DEVICE)\n",
    "model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "criterion = LOSS_FUNC()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.10"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/var/folders/r5/mzzh3rn14lgb2__wr5h7swqm0000gn/T/wandb/run-20230214_191328-zi9ka5sa</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/bhavye-mathur/MERRA2-U/runs/zi9ka5sa' target=\"_blank\">burning-candy-heart-4</a></strong> to <a href='https://wandb.ai/bhavye-mathur/MERRA2-U' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/bhavye-mathur/MERRA2-U' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-U</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/bhavye-mathur/MERRA2-U/runs/zi9ka5sa' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-U/runs/zi9ka5sa</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6e69e926d24445590f969902dd56adf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3502 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b32e2c0b2c04d938f2e13a21a3b01c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3502 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c951f4ac1e13434ea5888978d28075b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3502 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c32444bd37641e6b95bdfff7bacc29d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3502 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fb8e1583a954b128683b20a360d14bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3502 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6abfb02b9be44792a8137647d877fc1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=f\"MERRA2-{VARIABLE}\", dir=\"wandb-local\",\n",
    "           config={\"epochs\": EPOCHS,\n",
    "                   \"learning_rate\": LEARNING_RATE,\n",
    "                   \"batch_size\": BATCH_SIZE,\n",
    "                   \"estimate_quantile\": ESTIMATE_QUANTILE,\n",
    "                   \"layers\": HIDDEN_SIZES,\n",
    "                   \"dataset\": \"NGCT\"})\n",
    "\n",
    "wandb.watch(model, log_freq=100)\n",
    "model.train()\n",
    "\n",
    "\n",
    "def evaluate_one_epoch(epoch):\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in validation_dl:\n",
    "            prediction = model(inputs).squeeze()\n",
    "\n",
    "            mse += torch.nn.functional.mse_loss(prediction, targets)\n",
    "            mae += torch.nn.functional.l1_loss(prediction, targets)\n",
    "\n",
    "    n = len(validation_dl)\n",
    "    wandb.log({\"val_rmse\": ((mse / n) ** 0.5) * stds[VARIABLE]})\n",
    "    wandb.log({\"val_mae\": (mae / n) * stds[VARIABLE]})\n",
    "\n",
    "\n",
    "def train_one_batch(batch, batch_idx):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inputs, targets = batch\n",
    "\n",
    "    prediction = model(inputs).squeeze()\n",
    "    loss = criterion(prediction, targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            rmse = (torch.nn.functional.mse_loss(prediction, targets) ** 0.5) * stds[VARIABLE]\n",
    "            wandb.log({\"train_loss\": loss})\n",
    "            wandb.log({\"train_rmse\": rmse})\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    data = iter(train_dl)\n",
    "    for i in tqdm(range(len(train_dl))):\n",
    "        train_one_batch(next(data), i)\n",
    "\n",
    "\n",
    "def train():\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        train_one_epoch(epoch)\n",
    "        evaluate_one_epoch(epoch)\n",
    "\n",
    "\n",
    "sweep_configuration = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"name\": \"sweep\",\n",
    "    \"metric\": {\n",
    "        \"goal\": \"minimize\", \n",
    "        \"name\": \"val_rmse\"\n",
    "\t},\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [64, 128, 256, 512, 1024, 2048, 4096]},\n",
    "        \"learning_rate\": {\"max\": 0.1, \"min\": 0.0001},\n",
    "        \"layers\": {\"values\": []}\n",
    "     }\n",
    "}\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f\"MERRA2-{VARIABLE}\")\n",
    "# wandb.agent(sweep_id, function=main, count=4)\n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    batches = len(test_dl)\n",
    "    data = iter(test_dl)\n",
    "\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(batches)):\n",
    "            inputs, targets = next(data)\n",
    "            prediction = model(inputs).squeeze()\n",
    "\n",
    "            mse += torch.nn.functional.mse_loss(prediction, targets)\n",
    "            mse += torch.nn.functional.mse_loss(prediction, targets)\n",
    "\n",
    "    return (mse / batches) ** 0.5 * stds[VARIABLE], (mae / batches) * stds[VARIABLE]\n",
    "\n",
    "\n",
    "test_rmse, test_mae = test()\n",
    "\n",
    "\n",
    "print(f\"RMSE: {test_rmse} m/s\")\n",
    "print(f\"MAE:  {test_mae} m/s\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e03493def4e443d5bc69c8938912cf51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_rmse</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▅▃▂▁</td></tr><tr><td>val_rmse</td><td>█▆▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.00209</td></tr><tr><td>train_rmse</td><td>0.44944</td></tr><tr><td>val_mae</td><td>0.11355</td></tr><tr><td>val_rmse</td><td>0.25638</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">mesmerizing-ring-3</strong> at: <a href='https://wandb.ai/bhavye-mathur/MERRA2-U/runs/qctx6p6b' target=\"_blank\">https://wandb.ai/bhavye-mathur/MERRA2-U/runs/qctx6p6b</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>/var/folders/r5/mzzh3rn14lgb2__wr5h7swqm0000gn/T/wandb/run-20230214_190214-qctx6p6b/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
